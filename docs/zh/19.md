通过设计更具人类特质、需要更高智能水平的任务，我们对AI大语言模型进行了测试。以下是用于评估模型在这些任务中表现的用户提问示例。根据测试结果，模型在以下三个层级的任务中均表现出色：

- 层级1：详细列出本文的核心发现，并说明作者如何得出这些结论  
- 层级2：详细阐述本文中图[x]所展示的内容及证明的结论  
- 层级3：分析本文的详细优势与不足之处  

##### 4.1 综述性论文与原创研究论文的对比  
在首个案例中，我们要求ChatGPT分析Dai等人（2023）的综述论文的“优势与不足”（参见表8）。需要说明的是，这篇开放获取论文可在线免费查阅，我们在提问时仅提供了论文标题而未下载全文PDF。尽管该论文发表于大语言模型（GPT-3.5）的知识截止时间之后，但这并未影响模型对论文内容的精准评估。经作者团队验证，模型反馈中列出的所有“优势”条目以及“不足”中的第1、3、4条均具有合理性或堪称一针见血。作为对比，表9展示了新版Bing生成的同样精准且语境契合的回复。

在后续测试中，新版Bing对一篇生态综述论文（表10）的亮点进行了凝练总结，并对不足之处提出了中肯评价。值得注意的是，模型精准指出该文“缺乏明确指导综述分析的研究问题或目标”，这一批评恰反映了我们文中讨论的特质。第三个案例中，我们要求新版Bing分析一篇原创研究论文（表11）。由于该文献需订阅获取，我们通过下载全文PDF并在Microsoft Edge Dev浏览器中打开后进行提问。经论文原作者验证，模型反馈中“潜在优势”与“潜在不足”的归纳均准确无误，开篇提供的研究结论摘要也精准到位。

需要说明的是，当处理需要深度解析的请求时（例如分析论文中所有插图的表7案例），模型会在回复起始部分提供通用指导建议。这些建议不仅准确简洁，更体现了评估科研文献的正确方法论。  

我们进一步以Liu等人（2023）的研究论文为对象，要求模型（新版Bing）着重剖析其在研究方法、发现成果及讨论环节中存在的局限性。