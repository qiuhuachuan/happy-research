**表9** 展示了使用ChatGPT驱动的新版Bing在“更有创造力”模式下对Dai等人（2023年）所撰综述论文的评价。  
**提示语为**：分析这篇论文，详细说明其优点和不足。  
**模型回复如下**：要分析一篇科学论文，需仔细并批判性地阅读，评估其方法、结果、讨论与结论，并与该领域其他相关论文进行比较。根据系统提供的网页上下文，以下是该论文优缺点简要分析：  

**优点**：  
- 对近期中国因进口冷冻及冷藏食品经由污染物传播导致新冠疫情再次暴发的情况，进行了全面综述；  
- 总结了针对这些疫情开展的流行病学调查、实验室研究以及公共卫生部门采取的控制措施；  
- 探讨了这一特定传播途径对全球食品安全与生物安全的启示；  
- 论文结构清晰、参考文献详实、文字表达流畅。  

**不足**：  
- 论文主要依赖中国的官方报告和媒体消息，这些资料在数据质量、准确性和透明度上可能存在局限或偏差；  
- 未对不同国家和地区通过冷链食品造成污染物传播的风险因素、机制及流行程度进行系统性评估；  
- 未考虑其他可能导致疫情再次暴发的混杂因素或替代解释，例如人际传播、环境污染或病毒变异；  
- 未就如何在全球层面预防或减轻此类传播提出具体建议或指南。  

为生成该回复，我们下载了该综述论文的全文PDF，在Microsoft Edge Dev浏览器中打开，随后在侧边栏输入提示语，开启与新版Bing的对话。回复中使用了项目符号以使内容更清晰。  

实际上，模型所指出的亮点与不足，确实能为作者和审稿人提供有价值的补充参考——尤其当用户（例如审稿人）对该研究领域的文献背景不熟悉，或是时间有限、无法通过广泛查阅文献来将所评论文置于更广阔的学术背景中进行分析时。  

为进一步评估模型与人类专家相比的能力，我们对自己此前提交的稿件进行了额外测试，以验证大语言模型是否能胜任同行评审的角色。我们发现，在多数情况下，即使使用引导式提示，模型仍无法识别这些稿件中存在的具体问题（例如审稿人在同行评审过程中提出且作者同意修改的那些问题）。鉴于处理具体问题是同行评审的一部分，显然ChatGPT目前的能力尚不能真正替代人类审稿人。总而言之，我们认为当前ChatGPT能够对研究论文提供准确且有价值的一般性评论，但无法像同行评审那样针对稿件中的具体问题给出足够有针对性的意见。