根据用户提示中“提供广泛的研究范围（例如30篇或更多出版物）”的要求，这是ChatGPT及其衍生应用（如新版Bing）普遍存在的局限性。当提示需要生成长文本输出时，模型要么会提供简略版答案（例如表27），要么会先给出具体操作指引，再附注单个案例让用户自行扩展——这在先前案例（表7）中已有体现：当要求模型解释研究论文中所有图表时，它仅解析了一个图表并附上操作指南。

综上所述，表24、25、26和27的案例展示了向ChatGPT发送渐进式查询的典型工作流程：首先通过简单提示获取包含步骤的通用任务清单；继而要求模型对具体任务进行细化说明；最后获取相关参考文献以进行“真实性核验”。此外，用户还可进一步索取化学试剂、仪器设备、防护装备的采购清单，以及质量保证/质量控制流程和安全规范。

【注意事项】  
使用大语言模型辅助实验设计时需注意三点：首先，在对话结束时务必要求模型提供与实验设计相关的参考文献。如模型运行正常（如表27示例），研究者能即时获得高质量文献索引，也可配合Perplexity Ask等智能检索工具。随后需仔细核对文献方法与模型建议的一致性，这是确保方案符合学界共识的关键验证步骤。  

其次，必须警惕涉及安全风险的实验。操作者需严格遵循实验室安全规范，包括查阅材料安全数据表、佩戴防护装备，必要时须获得实验室安全负责人批准。需注意：大语言模型无法为现实场景中因疏漏导致的严重后果承担任何责任。  

最后且最重要的是，仅可将该技术用于科研教育等合法目的，严禁合成违禁药物、有毒物质、爆炸物或生物危害品等威胁环境与公共安全的非法活动。