在向大语言模型或其衍生应用上传原创或专有内容时，用户务必注意潜在的数据安全与隐私风险。这同样适用于用户与模型交互时输入的文本指令。

科学家可积极参与大语言模型及其他AI工具的开发与伦理实践，以推动其领域发展。凭借专业知识和技能，科学家有望与模型开发者协同合作，针对具体科研任务定制化开发未来模型，同时确保数据安全与伦理合规。

##### 14.2 亟待完善的功能
基于当前测试结果及AI大语言模型在可预见未来对科研日益显著的影响，我们向AI大语言模型及相关技术开发者提出以下建议。首先，我们主张在后续模型开发中实现或完善以下功能：

- 在公开版ChatGPT（GPT-3.5）界面中增设文档上传选项（需支持PDF、TXT、RTF、Word、LaTeX等文档格式，以及图像和数据文件如CSV、Excel），且无需付费或注册账户即可使用
- 采用包含准确文献信息的研究成果进行模型训练：确保获取完整的文献元数据（包括标题、作者、期刊名称、出版年份、卷期页码、DOI及关键词与摘要），这些信息即使对于订阅制出版物也通常可免费获取。开发者应将其纳入训练数据，以避免向用户提供错误文献信息或无效链接
- 将科研论文的补充材料纳入分析范围：这些由作者上传的文档常包含与主论文相关的重要信息，应与主文献同步分析以全面理解研究成果。鉴于多数科学期刊允许作者上传补充材料，AI大模型执行相关任务时应默认启用此功能
- 通过引文与作者学术记录实现信息源加权：在对论文内容进行在线检索时，优先采纳以下来源的信息：（i）被分析文献正文引用的参考文献