图中未提供相关说明（参见图 3 转载的图注）。经过对模型反馈的验证，我们得出结论：这些答案必须通过分析全文才能生成，而非简单转述论文特定段落的内容。例如，在示例分析的第一段中，模型将多数省份的宏观塑料分布描述为"偏态"，这一表述在黄等人（2020）的论文中并未出现，却精准把握了该图所呈现的数据本质。总体而言，搭载 ChatGPT 的新版 Bing 对图表内容的解读基本准确。

该模型能够识别图表与其描述（图注）、作者对图表的讨论文本以及图表在论文中的存在目的——即图表所支撑的具体论点和结果的重要性。通过简短直观的提示，用户可快速理解科研文献中看似复杂的图表，尤其适用于那些未以"独立呈现"方式准备的图表（例如图注未包含对结果的解读或未提供核心结论）。

需要特别说明的是，根据官方描述，新版 Bing 内置的大语言模型（GPT-4）具备独立解析孤立图像的能力（Microsoft 2023b）。这项称为"多模态视觉搜索"的功能允许用户针对图像、绘图或图表向 ChatGPT 及其衍生应用（如新版 Bing）提问，模型会尝试理解图像内容并进行解读。例如，用户可直接将图像"拖放"至新版 Bing 的聊天窗口使用此功能（Microsoft 2023b）。该功能适用于通用场景下的独立图像解析（如照片、艺术作品），或在全文缺失时分析特定图表。然而，通过将图表与原文中的相关文本及具体论点建立关联，模型能实现更精准且贴合语境的解读，这对科研出版物中面向专业读者的图表解析尤为重要。

本阶段主要发现如下：

- 我们重点探讨了运用搭载 ChatGPT 的新版 Bing 快速解析科研论文中复杂图表（如高光谱图像和数据图谱）的实践
- 模型通过通读全文，将每个图表与其描述文本、作者对结果的阐释进行关联，并识别图表在论文中支撑的具体结论或论点。经作者验证，模型解读大体准确，仅存在少量偏差
- 图表常承载科研论文的关键证据与数据，但读者若不阅读全文则难以理解——尤其当图表呈现大量结果、复杂概念，或频繁使用未在图注中说明的符号与缩写时。大语言模型能协助用户在不阅读原文的情况下，通过深度解析图表在整体研究语境中展示的内容与论证依据，实现对复杂科研图表的理解。
