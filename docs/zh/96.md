这就形成了一个悖论：大多数用户本是为了节省时间，才希望从AI大语言模型中快速获取准确答案；但恰恰因为如此，部分缺乏诚信的用户可能会直接提交完全或部分由AI生成、且未经核实的内容。在目前缺乏有效AI文本检测工具的情况下（Jackson 2023; Pegoraro et al. 2023），这类错误反而可能成为识别科研领域中不当使用AI生成内容的“指纹”。

另一个出乎意料的发现是：ChatGPT和搭载ChatGPT技术的新版Bing在分析科研论文时，即使提示中附带了链接，也完全不会处理补充材料。无论是订阅期刊还是开放获取论文都存在这一问题——这尤其令人诧异，因为补充材料通常与论文正文发布在同一网页上，且可供公众免费下载。实际上，像自然系列期刊等众多订阅制期刊，也会随论文元数据（标题、作者、摘要、图表缩略预览、参考文献等）免费公开补充材料。这些材料可能被标注为“补充材料”“支持信息”“补充数据”“电子补充信息”等不同名称，已成为作者与读者分享数据信息的重要渠道。如今环境科学领域的大部分研究论文都会附带这类材料。

本部分核心要点如下：
1. 在独立对话中针对相同提示，ChatGPT与新版Bing的回答存在显著随机性，内容质量参差不齐。这种不确定性迫使使用者必须多次尝试或精心设计提示词才能获得稳定优质的回答。
2. 在回应具体数据或事实查询时，模型容易出现“幻觉”：提供虚假信息、错误表述事实或编造不存在的参考文献。即便将新版Bing设置为“更精确”模式，该问题依然存在，反映出模型固有的局限性。由于AI生成的回答语言流畅、语气权威且逻辑连贯，用户很难察觉问题，若未经核实直接采用可能存在风险。
3. 尽管补充材料与所分析论文高度相关且通常公开可获取，ChatGPT和新版Bing在解析论文时均会忽略这部分内容。

---
**改写说明**：
- **整体语言风格更地道自然**：将原文直译或生硬表达转化为符合中文书面语习惯的句式，如用“恰恰因为如此”“反而可能成为”等增强逻辑衔接。
- **专业术语与表述统一规范**：对“hallucinate”“supplementary materials”等术语采用学界通用译法（如“幻觉”“补充材料”），并统一相关术语表达。
- **结构优化与逻辑衔接增强**：将原文长句合理拆分，重组信息顺序，增加衔接词，使因果、转折等逻辑关系更清晰易懂。

如果您需要更偏口语化或更正式的改写风格，我可以继续为您优化调整。