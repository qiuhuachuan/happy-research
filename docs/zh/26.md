（以下内容已进行地道化处理，代码及表格内容按原样保留）

在批评意见的表达上，AI 往往更倾向于笼统概括。虽然可以通过优化指令引导模型输出更具体的评论——正如我们在表 12 示例中所做的那样——但这需要投入大量时间进行后期事实核查，对于希望完全或主要依赖 AI 生成审稿意见的用户而言，反而违背了提升效率的初衷。

另一个显著特征体现在文本表达层面。根据我们的观察，AI 生成的文字在简洁性、连贯性和语言打磨程度上，已然超越了环境科学领域大多数已发表论文和手稿的写作水准。即便暂不考虑科学内容本身，其精雕细琢的文本质感如同观赏精密的机械艺术品。如同我们的体验，读者在阅读 AI 生成的英文文本时，可能会产生如同阅读专业作家作品般的震撼感。这种流畅得不真实的语言表达，对于以英语为第二语言的早期科研人员而言尤为明显。

本节核心要点总结：

- 作者与审稿人必须警惕使用大语言模型处理未发表或受版权保护内容时可能引发的知识产权、保密及隐私风险
- 科学出版机构近期已更新 AI 使用规范：Springer Nature 正研发更安全的审稿专用工具，目前不建议向 AI 工具上传未发表内容，并要求声明 AI 在审稿中的参与度；Elsevier 则完全禁止在同行评审中使用生成式 AI 技术
- 尽管当前 AI 评估科研产出存在局限性与风险，但 GPT-3.5/4 的实践表现已展现其潜力。随着技术演进及数据安全问题的解决，这类工具或将成为科研出版领域的重要助力
- 使用者务必遵循所在机构及出版方的 AI 使用政策，对 AI 生成信息进行严格验证后方可使用
- 期刊编辑通常能识别 AI 生成的审稿意见：这类评论往往泛泛而谈，缺乏对稿件的针对性指正；而人类审稿人则能提供具体问题指向与整体评估，文字表达更直截了当且较少修饰
