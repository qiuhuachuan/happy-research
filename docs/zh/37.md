需要重述的内容主要包含以下要点：

（注意：模型回复中列出的第三点与审稿人的核心批评无关。和前面某个例子（表16）类似，这次模型又偏离了重点。除此之外，模型提供的事实和引用链接经过作者核实是正确的。）

以下是我们在本小节的主要发现：

- 我们测试了搭载ChatGPT的新版Bing，看它能否协助撰写针对科研论文批评意见的 rebuttal（回应）。这些审稿意见不仅批判性强且紧扣具体内容，要求对研究论文中的证据、论证有深入理解，还需具备相关文献背景知识，这对大语言模型来说是项颇具挑战的任务。

- 总体而言，该模型展现了令人印象深刻的能力，能够通过寻找支撑证据并组织有说服力的论述，与人类专家进行细致的学术讨论和辩论。然而，有一个案例中，模型回避了评论中提出的问题，未能直击批评要点。此外，模型的回复中包含过时信息——这是大语言模型因知识截止日期固有的问题。这些例子凸显了使用ChatGPT处理科学工作中的具体评论时，需要人为监督。

- 在遵循期刊出版社和研究机构政策的前提下，这类工具可以辅助科研人员准备对同行评审批评意见的回复。

##### 6.2 回答问题

我们还测试了AI大语言模型帮助作者回答审稿人就近期研究论文（表19）具体内容提出问题的能力。为此，我们向模型提供了我们修订后的手稿和补充数据（即已发表的版本），但没有给出任何提示或我们实际的回复。

在这个例子中，审稿人在一组评论里提了两个问题。模型通过编号将它们分开，然后对每个问题逐一进行了回应（表19）。为了提升回复的清晰度，模型使用了**粗体**和*斜体*来区分审稿人的评论、摘录自手稿的文本以及它自己的回复——这种方法也正是我们在指导学生准备回复审稿意见时会传授的技巧。值得注意的是，所有这些都是在用户提示中没有明确要求的情况下，由模型自主完成的。

在此次测试中，我们要求模型仅使用所引用手稿中的信息来回应审稿人的评论，目的是限制模型使用其他来源（如网络信息或二手资料，这些更可能导致模型回复出错）的信息。首先，模型在“回复1”中提供的答案准确且简洁，这一点我们通过论文全文和补充数据（Liu et al. 2023）进行了核实。其次，值得注意的是，模型在回应具体评论前，先向审稿人表达了感谢，即“感谢您对我们……